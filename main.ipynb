{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as kungfupanda                    # pandas for data manipulation and markdown\n",
    "from pandas import DataFrame                    # export\n",
    "\n",
    "from os import listdir                          # for file retrieval and path calculations\n",
    "from os.path import isfile, join\n",
    "from os import stat\n",
    "\n",
    "from os.path import isdir                       # for creation of topic markdown folder if \n",
    "from os import mkdir                            # not present\n",
    "\n",
    "from os import getcwd                           # gets current working DIR for calculating git \n",
    "                                                # root of submissions folder \n",
    "\n",
    "from os import chdir                            # for changing the working directory to ensure\n",
    "from os.path import abspath, dirname            # relative paths used are from this script's\n",
    "import sys                                      # location rather than the calling location\n",
    "                                                # e.g. if you call `python someFolder/main.py`\n",
    "                                                #      then it will still work.\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from os.path import getmtime, getctime          # retreiving file creation/modification times\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from os import getenv, environ                  # for environment variables\n",
    "from dotenv import load_dotenv, find_dotenv     # for config purposes (.env file)\n",
    "\n",
    "from typing import Set, Dict, List, Tuple       # misc. QOL imports\n",
    "from collections import defaultdict\n",
    "from icecream import ic                         # for debugging / outputs\n",
    "\n",
    "import re                                       # for regex file name matching / question number matching\n",
    "\n",
    "import argparse                                 # For command line arguments when calling py script with flags\n",
    "import pickle                                   # for saving/loading json records and file \n",
    "                                                # modification date history\n",
    "\n",
    "from functools import cache                     # for redundancy protection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Configuration\n",
    "#### `.env` variables and `working directories`\n",
    "1. Loads `env` variables for reference.\n",
    "    1. Tries to retrieve it from `../` if found (prioritizing template).\n",
    "    2. If failure, use the `.env` found in the current script directory (in the updater).\n",
    "2. If is a script run, denotes it as such for script flag references and ensures working directory is the script's location rather than the calling directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading env variables\n",
    "if '.env' in listdir('../') :\n",
    "    print('.env found in ../ directory')\n",
    "    load_dotenv(find_dotenv('../.env'), override=True)\n",
    "else :\n",
    "    print('.env found in script directory')\n",
    "    load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# NOTE: if the script is being run from a jupyter notebook, then it should\n",
    "# already be in the correct directory.\n",
    "IS_NOTEBOOK = True\n",
    "try:\n",
    "    if 'ipykernel' not in sys.modules:\n",
    "        print('Working directory being set to script location.')\n",
    "        IS_NOTEBOOK = False\n",
    "        chdir(dirname(abspath(__file__)))\n",
    "    else :\n",
    "        print('Working directory already set to script location. No need for adjustment')\n",
    "except NameError:\n",
    "    print('NameError')\n",
    "    pass\n",
    "\n",
    "\n",
    "# README_ABS_DIR will get confirmed in if name==main prior to running\n",
    "README_ABS_DIR = getcwd().replace('\\\\', '/')\n",
    "NOTEBOOK_ABS_DIR = README_ABS_DIR\n",
    "print(f'{NOTEBOOK_ABS_DIR = }')\n",
    "MAIN_DIRECTORY = NOTEBOOK_ABS_DIR[NOTEBOOK_ABS_DIR.rfind('/')+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "README_PATH                 = getenv('README_PATH')\n",
    "LEETCODE_PATH_FROM_README   = getenv('QUESTIONS_PATH_FROM_README')\n",
    "LEETCODE_PATH_REFERENCE     = join(README_PATH, LEETCODE_PATH_FROM_README)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods\n",
    "\n",
    "AddCase $\\rightarrow$ takes information for a new question file and formats it accordingly for a row.\n",
    "\n",
    "UpdateLanguage $\\rightarrow$ if a question already has a solution, this is called instead to insert the new file link to the existing row details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories besides those in lists\n",
    "PRIMARY_CATEGORIES = set(['Daily', 'Weekly Premium', 'Contest', 'Favourite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individualCTimeViaGit(cmd: List[str]) -> Tuple[datetime, datetime] :\n",
    "    process = subprocess.Popen(cmd,\n",
    "                               shell=False,\n",
    "                               stdin=None,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE)\n",
    "    result = process.stdout.readlines()\n",
    "    modifiedTimes = []\n",
    "\n",
    "    if len(result) >= 1:\n",
    "        for line in result:\n",
    "            modifiedTimes.append(line.decode(\"utf-8\").replace('\\n', ''))\n",
    "    \n",
    "    # In case of a redundant '\\n' at the end of an output\n",
    "    if modifiedTimes[-1] == '':\n",
    "        modifiedTimes.pop()\n",
    "    \n",
    "    try :\n",
    "        creationDate = datetime.strptime(time.ctime(int(modifiedTimes[0])), '%a %b %d %H:%M:%S %Y')\n",
    "        modifiedDate = datetime.strptime(time.ctime(int(modifiedTimes[-1])), '%a %b %d %H:%M:%S %Y')\n",
    "    except ValueError as ve:\n",
    "        print(f'Error in parsing {path}')\n",
    "        print(f'{modifiedTimes}')\n",
    "        print(ve)\n",
    "        exit()\n",
    "    \n",
    "    return (creationDate, modifiedDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ALL_GIT_CM_TIMES = {}\n",
    "def getAllCTimesViaGit(paths: List[str]) -> Dict[str, Tuple[datetime, datetime]] :\n",
    "    '''\n",
    "    WARNING: DO NOT USE LOCALLY. SLOW IF RAN LOCALLY.\n",
    "    \n",
    "    GITHUB ACTIONS ARE ABLE TO PERFORM THIS QUICKLY (~10s for the script for ~700 files) \n",
    "    BUT A LOCAL RUN OF `-g` CAN TAKE UPWARDS OF 10 MINUTES FOR THE SAMEN NUMBER OF FILES.\n",
    "\n",
    "    To avoid having to constantly swap directories, this function parses all the ctimes and mtimes \n",
    "    in one block of time. This gets activated with the `-g` flag. Default otherwise is to use the \n",
    "    regular `getctime` and `getmtime` functions locally which is much much faster. This only exists \n",
    "    to compensate for the inability for ctime and mtime checking with git actions.\n",
    "    '''\n",
    "    print(f'Beginning parsing of git logs for file creation and modification dates...')\n",
    "    print(f'Script path: {getcwd() = }')\n",
    "    chdir('../')\n",
    "    print(f'README path: {getcwd() = }')\n",
    "\n",
    "    cmd = r\"git log --follow --format=%ct --reverse --\".split()\n",
    "    output = {}\n",
    "\n",
    "    for i, path in enumerate(paths) :\n",
    "        path = join(LEETCODE_PATH_FROM_README, path)\n",
    "        output[path] = individualCTimeViaGit(cmd + [path])\n",
    "\n",
    "    # Usually I'd avoid using global for this but this is a personal project so it should be fine.\n",
    "    _ALL_GIT_CM_TIMES.update(output)\n",
    "    print(f'{_ALL_GIT_CM_TIMES = }')\n",
    "    \n",
    "    chdir(MAIN_DIRECTORY)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def getCtimesMtimesGitHistory(path: str) -> Tuple[datetime, datetime] :\n",
    "    '''\n",
    "    WARNING: DO NOT USE LOCALLY. SLOW IF RAN LOCALLY RELATIVE TO THE REGULAR CTIME FUNCTION.\n",
    "\n",
    "    IF RUNNING LOCALLY, RUN (getCtimeMtimesMain) I.E. WITHOUT THE `-g` FLAG.\n",
    "\n",
    "    The cost for a single file isn't significant however when you reach ~100+ files, \n",
    "    the cumulative wait can go into the minutes compared to the seconds it would take \n",
    "    with the regular `getctime` and `getmtime` functions (without the `-g` flag)\n",
    "    '''\n",
    "    path = path[path.find('/') + 1:]\n",
    "    chdir('../')\n",
    "    cmd = r\"git log --follow --format=%ct --reverse --\".split() + [f'{path}']\n",
    "\n",
    "    cmDates = individualCTimeViaGit(cmd)\n",
    "\n",
    "    chdir(MAIN_DIRECTORY)\n",
    "\n",
    "    return cmDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GIT_DATES = False\n",
    "\n",
    "@cache\n",
    "def getCtimeMtimesMain(path: str) -> Tuple[datetime, datetime] :\n",
    "    '''\n",
    "    Returns the a tuple containing the datetime objs of \n",
    "    (create date and time, modification date and time)\n",
    "\n",
    "    @param useGitDates: bool = False\n",
    "        If true, it will track the creation/modification dates of the file \n",
    "        according to the git history. This is mainly to counter the issue in \n",
    "        GitHub actions where the file creation date is the time of the action.\n",
    "    '''\n",
    "    \n",
    "    if USE_GIT_DATES :\n",
    "        return getCtimesMtimesGitHistory(path)\n",
    "    \n",
    "    creation_date = time.ctime(getctime(path))\n",
    "    modification_date = time.ctime(getmtime(path))\n",
    "\n",
    "    creation_date = datetime.strptime(creation_date, \"%a %b %d %H:%M:%S %Y\")\n",
    "    modification_date = datetime.strptime(modification_date, \"%a %b %d %H:%M:%S %Y\")\n",
    "\n",
    "    # I've sometimes encountered weird meta data issues so just as a precaution\n",
    "    if creation_date > modification_date :\n",
    "        return (modification_date, creation_date)\n",
    "    \n",
    "    return (creation_date, modification_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCtimeMtimes(path: str, *, preCalculated: Dict[str, Tuple[datetime, datetime]] = None) -> Tuple[datetime, datetime] :\n",
    "    # Due to readme realtive and script relative paths\n",
    "    readme_path = path if ('../' not in path) else path[path.find('../') + len('../'):]\n",
    "    if _ALL_GIT_CM_TIMES and readme_path in _ALL_GIT_CM_TIMES :\n",
    "        return _ALL_GIT_CM_TIMES[readme_path]\n",
    "    \n",
    "    if preCalculated and readme_path in preCalculated :\n",
    "        return preCalculated[readme_path]\n",
    "\n",
    "    return getCtimeMtimesMain(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addCase(level:              str,\n",
    "            number:             int, \n",
    "            title:              str, \n",
    "            categories:         Set[str],\n",
    "            language:           str,\n",
    "            notebook_path:      str,\n",
    "            readme_path:        str,\n",
    "            fileLatestTimes:    dict,\n",
    "            contestTitle:       str=None,\n",
    "            contestQNo:         str=None) -> dict :\n",
    "    '''\n",
    "    Takes the data found on a question not encountered before and \n",
    "    converts it into a callable dictionary with all the relevant \n",
    "    information\n",
    "\n",
    "    ### Parameters (Required) :\n",
    "    level : str\n",
    "        Difficulty indicator of the question (e, m, h)\n",
    "    number : int\n",
    "        The official LeetCode question number\n",
    "    title : str\n",
    "        The title of the question (colloquial name)\n",
    "    categories : Set[str]\n",
    "        The categories the question falls under (e.g. Contest, Daily, etc.)\n",
    "    language : str\n",
    "        The programming language used to solve the question\n",
    "    notebook_path : str\n",
    "        The path from the main.py/ipynb script to the code file in question\n",
    "    readme_path : str\n",
    "        The path from the README.md file to be exported to the code file in question\n",
    "    fileLatestTimes : dict\n",
    "        A dictionary containing the latest modification times of all files\n",
    "        in the repository\n",
    "    \n",
    "    ### Parameters (Optional) :\n",
    "    contestTitle : str\n",
    "        The title of the contest the question was a part of if applicable\n",
    "    contestQNo : str\n",
    "        The question number in the contest if applicable (e.g. q1, q2, etc.)\n",
    "\n",
    "    ### Returns :\n",
    "    output : dict\n",
    "        A dictionary containing all the relevant information for the question\n",
    "        to be used in the final output\n",
    "    '''\n",
    "\n",
    "    creation_date, modification_date = getCtimeMtimes(notebook_path)\n",
    "    fileLatestTimes[readme_path] = modification_date\n",
    "\n",
    "    try :\n",
    "        fileSize = stat(notebook_path).st_size\n",
    "    except FileNotFoundError as fnfe :\n",
    "        fileSize = 0\n",
    "        print(fnfe)\n",
    "    \n",
    "\n",
    "    if not categories :\n",
    "        categories = set()\n",
    "\n",
    "    if 'e' in level.lower() :\n",
    "        level = 'Easy'\n",
    "    elif 'm' in level.lower() : \n",
    "        level = 'Medium'\n",
    "    elif 'h' in level.lower() :\n",
    "        level = 'Hard'\n",
    "    else :\n",
    "        level = 'Unknown'\n",
    "\n",
    "    output = {\n",
    "                'level':                level,\n",
    "                'number':               number,\n",
    "                'title':                title, \n",
    "                'categories':           categories,\n",
    "                'contestTitle':         contestTitle,\n",
    "                'contestQNo':           contestQNo,\n",
    "                'date_done':            creation_date,          # First time completed\n",
    "                'date_modified':        modification_date,      # Most recent date\n",
    "                'solution':             '',\n",
    "                'solutions':            {language: [readme_path]},\n",
    "                'languages':            set([language]),\n",
    "                'bytes':                fileSize\n",
    "             }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateQuestion(orig:               dict, \n",
    "                   *,\n",
    "                   language:           str,\n",
    "                   categories:         Set[str],\n",
    "                   notebook_path:      str,\n",
    "                   readme_path:        str,\n",
    "                   fileLatestTimes:    dict,\n",
    "                   contestTitle:       str=None,\n",
    "                   contestQNo:         str=None) -> dict :\n",
    "    '''\n",
    "    Takes question data of a question that's already been encountered and \n",
    "    updates the relevant dictionary with the new information found. Similar \n",
    "    to addCase but for questions that have already been encountered.\n",
    "\n",
    "    ### Parameters :\n",
    "    orig : dict\n",
    "        The original dictionary containing all the relevant information from previous encounters\n",
    "    \n",
    "    All other parameters are the same as addCase and are optional in order to update them.\n",
    "        \n",
    "    ### Returns :\n",
    "    orig : dict\n",
    "        The updated dictionary containing all the relevant information from previous encounters\n",
    "    '''\n",
    "    \n",
    "    # Another question file found\n",
    "    if language and language not in orig['languages'] :\n",
    "        orig['languages'].add(language)\n",
    "\n",
    "    if contestTitle :\n",
    "        orig['contestTitle'] = contestTitle\n",
    "        \n",
    "    if contestQNo :\n",
    "        orig['contestQNo'] = contestQNo\n",
    "          \n",
    "    if categories :\n",
    "        orig['categories'] |= categories\n",
    "\n",
    "    if notebook_path and readme_path :\n",
    "        creation_date, modification_date = getCtimeMtimes(notebook_path)\n",
    "        \n",
    "        if creation_date < orig['date_done'] :\n",
    "            orig['date_done'] = creation_date\n",
    "        if modification_date > orig['date_modified'] :\n",
    "            orig['date_modified'] = modification_date\n",
    "            fileLatestTimes[readme_path] = modification_date\n",
    "\n",
    "        if language not in orig['solutions'] :\n",
    "            orig['solutions'][language] = []\n",
    "        orig['solutions'][language].append(readme_path)\n",
    "\n",
    "        try :\n",
    "            fileSize = stat(notebook_path).st_size\n",
    "        except FileNotFoundError as fnfe :\n",
    "            fileSize = 0\n",
    "            print(fnfe)\n",
    "        orig['bytes'] += fileSize\n",
    "  \n",
    "    return orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def retrieveQuestionDetails() -> dict :\n",
    "    '''\n",
    "    Retrieves the question details (i.e. title, acRates, difficulties, etc.) from\n",
    "    the relevant `.pkl` file containing parsed official LeetCode json data.\n",
    "\n",
    "    ### Returns :\n",
    "    questionDetailsDict : dict[int, details]\n",
    "        A dictionary containing the question details matched to the question's assigned number\n",
    "    '''\n",
    "    \n",
    "    question_data_folder    = getenv('QUESTION_DATA_PATH')\n",
    "    question_details_file   = getenv('LEETCODE_QUESTION_DETAILS')\n",
    "\n",
    "    if not isfile(join(question_data_folder, question_details_file)) :\n",
    "        print('Rerunning json-to-pkl parse and export due to the file(s) not being found.')\n",
    "        print()\n",
    "        import parse_official_question_data\n",
    "        \n",
    "    if not isfile(join(question_data_folder, question_details_file)) :\n",
    "        print('\\nError in parsing official question data. Exiting...')\n",
    "        print()\n",
    "        exit()\n",
    "    else : \n",
    "        print('\\nFiles found. Importing now...\\n')\n",
    "\n",
    "\n",
    "    # schema: key=int(questionNumber)   val=(title, titleSlug, paidOnly, difficulty, acRate)\n",
    "    with open(join(question_data_folder, question_details_file), 'rb') as fp:\n",
    "        questionDetailsDict = pickle.load(fp)\n",
    "        # print('Question Details dictionary')\n",
    "        # print(questionDetailsDict)\n",
    "\n",
    "    return questionDetailsDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def retrieveQuestionTopics() -> dict :\n",
    "    '''\n",
    "    Retrieves the topics associated with each question (e.g. Array, LinkedList, \n",
    "    BST, etc.) from the relevant `.pkl` file containing parsed official LeetCode json data.\n",
    "\n",
    "    ### Returns :\n",
    "    questionDetailsDict : dict\n",
    "        A dictionary containing the question details matched to the question's assigned number\n",
    "    '''\n",
    "    \n",
    "    question_data_folder    = getenv('QUESTION_DATA_PATH')\n",
    "    question_topics_file   = getenv('LEETCODE_QUESTION_TOPICS')\n",
    "\n",
    "    if not isfile(join(question_data_folder, question_topics_file)) :\n",
    "        print('Rerunning json-to-pkl parse and export due to the file(s) not being found.')\n",
    "        print()\n",
    "        import parse_official_question_data\n",
    "        \n",
    "    if not isfile(join(question_data_folder, question_topics_file)) :\n",
    "        print('\\nError in parsing official question data. Exiting...')\n",
    "        print()\n",
    "        exit()\n",
    "    else : \n",
    "        print('\\nFiles found. Importing now...\\n')\n",
    "\n",
    "    # schema: key-int(questionNumber)   val=List[str](topics)\n",
    "    questionTopicsDict = None\n",
    "    with open(join(question_data_folder, question_topics_file), 'rb') as fp:\n",
    "        questionTopicsDict = pickle.load(fp)\n",
    "        # print('Question Details dictionary')\n",
    "        # print(questionTopicsDict)\n",
    "\n",
    "    return questionTopicsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeRecentFileTimes(fileLatestTimes: dict) -> bool :\n",
    "    '''Pickles the newly found most recent modification times of each question for reference in future runs'''\n",
    "    \n",
    "    history_path = join(getenv('USER_DATA_PATH'), getenv('FILE_MODIFICATION_NAME'))\n",
    "\n",
    "    with open(history_path, 'wb') as fp:\n",
    "        pickle.dump(fileLatestTimes, fp)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecentFileTimes() -> dict :\n",
    "    '''Retrieves the pickled data from previous cases of `writeRecentFileTimes()`'''\n",
    "    \n",
    "    history_path = join(getenv('USER_DATA_PATH'), getenv('FILE_MODIFICATION_NAME'))\n",
    "\n",
    "    if isfile(history_path) :\n",
    "        with open(history_path, 'rb') as fp:\n",
    "            return pickle.load(fp)\n",
    "        \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Files\n",
    "Question file parsing occurs here. It organizes it into 3 different lists, separated by difficulty and sorted by question number afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse one leetcode answer file in the submissions folder\n",
    "def parseCase(leetcodeFile:         str,  # file name\n",
    "              questionData:         dict, # dictionary of question data\n",
    "              fileLatestTimes:      dict,\n",
    "              reprocessMarkdown:    set,\n",
    "              *,\n",
    "              questionDetailsDict:  dict = retrieveQuestionDetails(),\n",
    "              subFolderPath:        str = '',\n",
    "              altTitle:             str = '',\n",
    "              contest:              str = None,\n",
    "              contestQNo:           str = None) -> bool:\n",
    "\n",
    "    path = join(LEETCODE_PATH_FROM_README, subFolderPath, leetcodeFile).replace(\"\\\\\", \"/\")\n",
    "\n",
    "    number      = int(re.search(\"\\d{1,4}\", leetcodeFile).group())   # Takes the first full number as the question\n",
    "    level       = questionDetailsDict[number][3][0].lower()     # number and uses that as reference\n",
    "                                                                # e.g. 'e123 v1.py' becomes 123\n",
    "\n",
    "    creationtime, modificationtime = getCtimeMtimes(join(README_PATH, path))\n",
    "\n",
    "    if path not in fileLatestTimes or max(creationtime, modificationtime) > fileLatestTimes[path] :\n",
    "        reprocessMarkdown.add(number)\n",
    "        fileLatestTimes[path] = max(creationtime, modificationtime)\n",
    "        \n",
    "\n",
    "    if number in questionDetailsDict :\n",
    "        title   = f'[{questionDetailsDict[number][0]}](<https://leetcode.com/problems/{questionDetailsDict[number][1]}>)'\n",
    "    else :\n",
    "        title   = f'Question {number}'\n",
    "    categories  = set()\n",
    "    language    = leetcodeFile[leetcodeFile.rfind('.') + 1:]\n",
    "\n",
    "    if len(altTitle) > 0 :\n",
    "        title = altTitle + ' - ' + title\n",
    "\n",
    "    # Question is from a contest folder\n",
    "    if contest :\n",
    "        temp = re.findall('q\\d{1}', leetcodeFile)                       # Checking if file name has a question number (e.g. q1 of the contest)\n",
    "        if not len(temp) == 0 :\n",
    "            contestQNo = temp[0]\n",
    "\n",
    "        categories.add('Contest')\n",
    "\n",
    "\n",
    "    for cat in PRIMARY_CATEGORIES :\n",
    "        if cat.lower() in leetcodeFile.lower() :\n",
    "            categories.add(cat)\n",
    "\n",
    "    if number in questionData :                                     # If solution already found for this question\n",
    "        questionData[number] = updateQuestion(questionData[number], \n",
    "                                              language=language, \n",
    "                                              categories=categories, \n",
    "                                              notebook_path=join(README_PATH, path), \n",
    "                                              readme_path=path,\n",
    "                                              contestTitle=contest,\n",
    "                                              contestQNo=contestQNo,\n",
    "                                              fileLatestTimes=fileLatestTimes)\n",
    "        return True\n",
    "    \n",
    "    questionData[number] = addCase(level=level, \n",
    "                                   number=number, \n",
    "                                   title=title,\n",
    "                                   categories=categories, \n",
    "                                   language=language, \n",
    "                                   notebook_path=join(README_PATH, path), \n",
    "                                   readme_path=path,\n",
    "                                   contestTitle=contest,\n",
    "                                   contestQNo=contestQNo,\n",
    "                                   fileLatestTimes=fileLatestTimes)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def getCodeFiles() -> List[str] :\n",
    "    return [x for x in listdir(LEETCODE_PATH_REFERENCE) if isfile(join(LEETCODE_PATH_REFERENCE, x))\n",
    "                                                           and not x.endswith('.txt')\n",
    "                                                           and not x.endswith('.md')\n",
    "                                                           and '.' in x]\n",
    "\n",
    "@cache\n",
    "def getContestFolders() -> List[str] :\n",
    "    return [x for x in listdir(LEETCODE_PATH_REFERENCE) if not isfile(join(LEETCODE_PATH_REFERENCE, x))]\n",
    "\n",
    "@cache\n",
    "def getContextFiles(contestFolders: List[str] = getContestFolders()) -> List[str] :\n",
    "    output = [x for x in listdir(LEETCODE_PATH_REFERENCE) if isfile(join(LEETCODE_PATH_REFERENCE, x)) \n",
    "                                                             and (x.endswith('.txt') \n",
    "                                                                  or x.endswith('.md') \n",
    "                                                                  or '.' not in x)]\n",
    "    for folder in contestFolders :\n",
    "        output.extend([join(folder, y) for y in listdir(join(LEETCODE_PATH_REFERENCE, folder)) \n",
    "                                if isfile(join(LEETCODE_PATH_REFERENCE, folder, y))\n",
    "                                   and (y.endswith('.txt') \n",
    "                                        or y.endswith('.md') \n",
    "                                        or '.' not in y)])\n",
    "    return output\n",
    "\n",
    "def getContestFiles(contestFolders: List[str]) -> List[Tuple[str, str]] :\n",
    "    contestLeetcodeFiles    = []\n",
    "\n",
    "    for contestFolder in contestFolders :\n",
    "        contestLeetcodeFiles.extend([(contestFolder, fileName) for fileName in listdir(join(LEETCODE_PATH_REFERENCE, contestFolder)) \n",
    "                                                                if isfile(join(LEETCODE_PATH_REFERENCE, contestFolder, fileName))\n",
    "                                                                    and not fileName.endswith('.txt')\n",
    "                                                                    and not fileName.endswith('.md')\n",
    "                                                                    and '.' in fileName])\n",
    "    \n",
    "    return contestLeetcodeFiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort TXT Context\n",
    "If .txt notes are placed, this adds them to their respective entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseContextFiles(txtFiles: str, \n",
    "                      questionData: dict,\n",
    "                      fileLatestTimes: dict, \n",
    "                      reprocessMarkdown: Set[int]) -> None:\n",
    "    for fileName in txtFiles :\n",
    "        print(f'Context file found: {fileName}')\n",
    "\n",
    "        if '\\\\' in fileName :\n",
    "            number = int(re.search(\"\\d{1,4}\", fileName[fileName.find('\\\\') + 1:]).group())\n",
    "        elif '/' in fileName :\n",
    "            number = int(re.search(\"\\d{1,4}\", fileName[fileName.find('/') + 1:]).group())\n",
    "        else :\n",
    "            number = int(re.search(\"\\d{1,4}\", fileName).group())\n",
    "        if number not in questionData :\n",
    "            print(f'Error. No question solution found for context file ({fileName = })')\n",
    "            continue\n",
    "        \n",
    "        questionData[number]['contextFile'] = join(LEETCODE_PATH_FROM_README, fileName)\n",
    "        path = join(LEETCODE_PATH_REFERENCE, fileName)\n",
    "        \n",
    "        creationtime, modificationtime = getCtimeMtimes(path)\n",
    "        if path not in fileLatestTimes or max(creationtime, modificationtime) > fileLatestTimes[path] :\n",
    "            fileLatestTimes[path] = max(creationtime, modificationtime)\n",
    "            reprocessMarkdown.add(number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List-Based Categories\n",
    "Updating `Category` columns based on the lists in the `Lists` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LISTSDIR = getenv('LISTS_LOCATION')\n",
    "\n",
    "@cache\n",
    "def getLists() -> List[str] :\n",
    "\n",
    "    listFileNames = [x for x in listdir(LISTSDIR) if isfile(join(LISTSDIR, x)) \n",
    "                                                    and not x.startswith('.')\n",
    "                                                    and not x == 'README.md']\n",
    "    print(listFileNames)\n",
    "\n",
    "    return listFileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Format for lists file is as follows:\n",
    "\n",
    "        [Question #]. [Question Name]\n",
    "\n",
    "        [Easy, Med., Hard]\n",
    "        Topic1\n",
    "        Topic2\n",
    "        Topic3\n",
    "        ...\n",
    "'''\n",
    "\n",
    "@cache\n",
    "def getList(fileName, filePath) -> set[int] :\n",
    "    output = set() # can change to dict later if we want to output category info\n",
    "\n",
    "    count = 0\n",
    "    with open(filePath, 'r') as file :\n",
    "        lines = file.readlines()\n",
    "        for line in lines :\n",
    "            if re.match(r'\\d{1,4}\\.', line) :\n",
    "                count += 1\n",
    "                output.add(int(line[:line.find('.')]))\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processListData(questionData: dict,\n",
    "                    *,\n",
    "                    listFileNames: List[str] = getLists()) -> dict :\n",
    "    \n",
    "    listData = {}\n",
    "    for file in listFileNames :\n",
    "        listData[file] = getList(file, join(LISTSDIR, file))\n",
    "        for q in listData[file] :\n",
    "            if q in questionData :\n",
    "                questionData[q]['categories'].add(file)\n",
    "                \n",
    "    # print(listData)\n",
    "\n",
    "    return listData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Topic Grouping\n",
    "Parses the questions in `questionData` and adds their numbers to appropriate lists so that they can be parsed into their own lists as well as counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompletedQuestionsTopicLists(questionData: dict,\n",
    "                                    *,\n",
    "                                    questionTopicsDict: dict = retrieveQuestionTopics()) -> defaultdict :\n",
    "    \n",
    "    completedTopicLists = defaultdict(set)\n",
    "\n",
    "    for question in questionData.keys() :\n",
    "        if question not in questionTopicsDict :\n",
    "            continue\n",
    "        for topic in questionTopicsDict[question] :\n",
    "            completedTopicLists[topic].add(question)\n",
    "\n",
    "    return completedTopicLists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Markdown Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "README_PATH                     = getenv('README_PATH')\n",
    "QUESTIONS_FOLDER_FROM_README    = getenv('QUESTIONS_PATH_FROM_README')\n",
    "QUESTIONS_FOLDER                = join(README_PATH, QUESTIONS_FOLDER_FROM_README)\n",
    "\n",
    "MARKDOWN_PATH = getenv('QUESTION_MARKDOWNS_PATH_FROM_README')\n",
    "MARKDOWN_TO_SUBMISSIONS = '../' * MARKDOWN_PATH.count('/') + QUESTIONS_FOLDER_FROM_README\n",
    "\n",
    "QUESTION_DATA_FOLDER_PATH    = getenv('QUESTION_DATA_PATH')\n",
    "QUESTION_TOPICS_FILE         = getenv('LEETCODE_QUESTION_TOPICS')\n",
    "QUESTION_DETAILS_FILE        = getenv('LEETCODE_QUESTION_DETAILS')\n",
    "\n",
    "import json\n",
    "with open('question_data/language_equivs.json') as f :\n",
    "    LANGUAGE_EQUIVS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARKDOWN_TO_SUBMISSIONS\n",
    "def generate_markdown(questionNo: int, \n",
    "                      questionData: dict,\n",
    "                      *,\n",
    "                      questionDetailsDict: dict = retrieveQuestionDetails(),\n",
    "                      questionTopicsDict: dict = retrieveQuestionTopics(),\n",
    "                      export: bool = False) -> str :\n",
    "    if questionNo in questionData :\n",
    "        questionData = questionData[questionNo]\n",
    "\n",
    "    title = questionData[\"title\"]\n",
    "\n",
    "    # Only if title has already been modified and matched to a LeetCode url\n",
    "    # E.g. some contest files will be unmatched\n",
    "    if '[' in questionData[\"title\"] :\n",
    "        title = title[title.find('[') + 1:title.find(']')]\n",
    "\n",
    "    title = f'{questionNo}. {title}'\n",
    "    \n",
    "    generate_file_name = f'_{title}.md'\n",
    "    generate_path = join(README_PATH, MARKDOWN_PATH, generate_file_name)\n",
    "    output_path = join(MARKDOWN_PATH, generate_file_name)\n",
    "    \n",
    "    questionData['solution'] = generate_file_name\n",
    "\n",
    "    if not export :\n",
    "        return generate_path\n",
    "\n",
    "    with open(generate_path, 'w', encoding='utf-8') as f :\n",
    "        f.write(f'# {questionNo}. {questionData[\"title\"]}\\n\\n')\n",
    "\n",
    "        date_done = questionData['date_done']\n",
    "        date_modified = questionData['date_modified']\n",
    "        \n",
    "        f.write(f'*All prompts are owned by LeetCode. To view the prompt, click the title link above.*\\n\\n')\n",
    "        \n",
    "        if questionData['contestTitle'] and questionData['contestQNo']:\n",
    "            f.write(f'*Completed during {questionData[\"contestTitle\"]} ({questionData[\"contestQNo\"]})*\\n\\n')\n",
    "\n",
    "        f.write('*[Back to top](<../README.md>)*\\n\\n')\n",
    "\n",
    "        f.write('------\\n\\n')\n",
    "        f.write(f'> *First completed : {date_done:%B %d, %Y}*\\n>\\n')\n",
    "        f.write(f'> *Last updated : {date_modified:%B %d, %Y}*\\n')\n",
    "\n",
    "        f.write('\\n------\\n\\n')\n",
    "\n",
    "        BY_TOPIC_FOLDER_PATH = getenv('TOPIC_MARKDOWN_PATH_IN_MARKDOWNS_FOLDER')\n",
    "        tpcs = 'N/A' if questionNo not in questionTopicsDict or len(questionTopicsDict[questionNo]) == 0 \\\n",
    "                     else ', '.join([f'[{x}](<{join(BY_TOPIC_FOLDER_PATH, x)}.md>)' for x in questionTopicsDict[questionNo]])\n",
    "        \n",
    "        f.write(f'> **Related Topics** : **{tpcs}**\\n>\\n')\n",
    "\n",
    "        acrate = 'Unknown' if questionNo not in questionDetailsDict else f'{questionDetailsDict[questionNo][4]} %'\n",
    "        f.write(f'> **Acceptance Rate** : **{acrate}**\\n\\n')\n",
    "        f.write('------\\n\\n')\n",
    "\n",
    "        if 'contextFile' in questionData:\n",
    "            with open(join(README_PATH, questionData['contextFile']), 'r') as contextFile:\n",
    "                f.write('> ' + contextFile.read().replace('\\n', '\\n> '))\n",
    "            f.write(f'\\n\\n------\\n\\n')\n",
    "        \n",
    "\n",
    "        f.write(f'## Solutions\\n\\n')\n",
    "        for lang, solutions in questionData['solutions'].items() :\n",
    "            solutions.sort()\n",
    "            for solution in solutions :\n",
    "                name = solution[solution.find('/') + 1:]\n",
    "                f.write(f'- [{name}](<{join(README_PATH, solution)}>)\\n')\n",
    "\n",
    "        for lang, solutions in questionData['solutions'].items() :\n",
    "            if lang.lower() in LANGUAGE_EQUIVS :\n",
    "                lang = LANGUAGE_EQUIVS[lang.lower()]\n",
    "            else :\n",
    "                print()\n",
    "                print(f'Lang equiv not found: {lang = }')\n",
    "            f.write(f'### {lang}\\n')\n",
    "            for solution in solutions :\n",
    "                name = solution.rfind('/') + 1\n",
    "                f.write(f'#### [{solution[name:]}](<{join(README_PATH, solution)}>)\\n')\n",
    "                f.write(f'```{lang}\\n')\n",
    "                with open(join(README_PATH, solution), 'r', encoding='utf-8') as solutionFile:\n",
    "                    fileData = solutionFile.read()\n",
    "                    if '# @lc code=start' in fileData :\n",
    "                        lcStart = '# @lc code=start'\n",
    "                        lcEnd   = '# @lc code=end'\n",
    "                        fileData = fileData[fileData.find(lcStart) + len(lcStart):fileData.rfind(lcEnd)]\n",
    "                    f.write(fileData)\n",
    "                f.write('\\n```\\n\\n')\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMarkdownGeneration(questionData: dict,\n",
    "                              reprocessMarkdown: Set[int],\n",
    "                              *,\n",
    "                              questionDetailsDict: dict = retrieveQuestionDetails(),\n",
    "                              questionTopicsDict: dict = retrieveQuestionTopics()) -> None :\n",
    "    \n",
    "    # Create a folder to avoid errors if it doesn't already exist\n",
    "    markdownFolder = join(README_PATH, MARKDOWN_PATH)\n",
    "    if not isdir(markdownFolder) :\n",
    "        mkdir(markdownFolder)\n",
    "\n",
    "    for questionNo, dta in questionData.items() :\n",
    "        if questionNo in reprocessMarkdown :\n",
    "            generate_markdown(questionNo, \n",
    "                              questionData, \n",
    "                              questionDetailsDict=questionDetailsDict, \n",
    "                              questionTopicsDict=questionTopicsDict,\n",
    "                              export=True)\n",
    "        else : # In order to assign the markdown paths\n",
    "            generate_markdown(questionNo, \n",
    "                              questionData, \n",
    "                              questionDetailsDict=questionDetailsDict, \n",
    "                              questionTopicsDict=questionTopicsDict,\n",
    "                              export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "Conversion into DataFrames and declaration of respective column headers occurs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [ \n",
    "            '#',\n",
    "            'Title', \n",
    "            'Level',\n",
    "            'Cats',\n",
    "            'Solution',\n",
    "            'Languages',\n",
    "            'Date Complete'\n",
    "          ]\n",
    "\n",
    "TYPE_CLARIFICATION = {\n",
    "                      '#':                  int,\n",
    "                      'Title':              str, \n",
    "                      'Level':              str,\n",
    "                      'Cats':               str,\n",
    "                      'Solution':           str,\n",
    "                      'Languages':          str,\n",
    "                      'Date Complete':      str\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDataToMatrix(questionData: dict,\n",
    "                        *,\n",
    "                        sortBy:       str = 'number',\n",
    "                        includeDate:  bool = False,\n",
    "                        includeQuestions: set[int] = set(),\n",
    "                        relativeFolderAdjustment: int = 0,\n",
    "                        includeMarkdownFolder: bool = False) -> List[list] :\n",
    "    dataframe_array = []\n",
    "\n",
    "    for question in questionData.values() :\n",
    "        # If it's not an empty set and the value isn't in there, skip\n",
    "        if includeQuestions and question['number'] not in includeQuestions :\n",
    "            continue\n",
    "\n",
    "        if sortBy == 'number' and includeMarkdownFolder :\n",
    "            solution_path = join(MARKDOWN_PATH, question['solution'])    \n",
    "        else :\n",
    "            solution_path = question['solution']\n",
    "        \n",
    "        solution_path = '../' * abs(relativeFolderAdjustment) + solution_path\n",
    "\n",
    "        title_to_use = question['title']\n",
    "        \n",
    "        if question['contestTitle'] and question['contestQNo'] :\n",
    "            title_to_use = f'{question[\"contestTitle\"]} - {question[\"contestQNo\"]} - {title_to_use}'\n",
    "\n",
    "        currentRow = [question['number'],\n",
    "                      title_to_use, \n",
    "                      question['level'], \n",
    "                      ', '.join(sorted(list(question['categories']))), \n",
    "                      f'[solution](<{solution_path}>)', \n",
    "                      ', '.join(sorted(list(question['languages'])))]\n",
    "        \n",
    "        if includeDate :\n",
    "            currentRow.append(question['date_done'].strftime('%b %d, %Y'))\n",
    "        \n",
    "        dataframe_array.append(currentRow)\n",
    "\n",
    "    dataframe_array.sort(key=lambda x: questionData.get(x[0])[sortBy])\n",
    "    return dataframe_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertQuestionDataToDataframe(questionData: dict,\n",
    "                                   *,\n",
    "                                   sortBy: str = 'number',\n",
    "                                   includeDate:  bool = False,\n",
    "                                   includeQuestions: set[int] = set(),\n",
    "                                   relativeFolderAdjustment: int = 0,\n",
    "                                   includeMarkdownFolder: bool = False) -> DataFrame :\n",
    "    questionData = convertDataToMatrix(questionData, \n",
    "                                       sortBy=sortBy, \n",
    "                                       includeDate=includeDate, \n",
    "                                       includeQuestions=includeQuestions,\n",
    "                                       relativeFolderAdjustment=relativeFolderAdjustment,\n",
    "                                       includeMarkdownFolder=includeMarkdownFolder)\n",
    "    dfQuestions = kungfupanda.DataFrame()\n",
    "    if questionData :\n",
    "        dfQuestions   = kungfupanda.DataFrame(data=questionData, columns=COLUMNS[:len(questionData[0])])\n",
    "    \n",
    "    # dfQuestions   = dfQuestions.astype(TYPE_CLARIFICATION[:len(questionData[0])])\n",
    "\n",
    "    return dfQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List & Other Markdowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted by Most Recent\n",
    "Using creation dates of code files only; not modification dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Reversed due to default sorting being in ascending order\n",
    "def byRecentQuestionDataDataframe(questionData: dict) -> DataFrame :\n",
    "    return convertQuestionDataToDataframe(questionData, sortBy='date_done', includeDate=True).iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted by Amount of Code\n",
    "Questions with more files on the question and longer submissions will be prioritized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byCodeLengthDataDataframe(questionData: dict) -> DataFrame :\n",
    "    return convertQuestionDataToDataframe(questionData, sortBy='bytes', includeDate=True).iloc[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of Markdowns for Each Related Topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questionTopicDataframes(questionData: dict,\n",
    "                            *,\n",
    "                            topicGroupings: defaultdict) -> List[Tuple[str, int, DataFrame]] : # [topic, number of questions, dataframe]\n",
    "    if not topicGroupings :\n",
    "        topicGroupings = getCompletedQuestionsTopicLists(questionData)\n",
    "    \n",
    "    output = []\n",
    "    for topic, qs in topicGroupings.items() :\n",
    "        output.append((topic, \n",
    "                       len(qs), \n",
    "                       convertQuestionDataToDataframe(questionData,\n",
    "                                                      includeDate=True,\n",
    "                                                      includeQuestions=qs,\n",
    "                                                      relativeFolderAdjustment=-getenv('TOPIC_MARKDOWN_PATH_IN_MARKDOWNS_FOLDER').count('/'))))\n",
    "        \n",
    "    output.sort(key=lambda x: x[1], reverse=True)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_FOLDER = getenv('TOPIC_MARKDOWN_PATH_IN_MARKDOWNS_FOLDER')\n",
    "\n",
    "def topicBasedMarkdowns(questionData: dict,\n",
    "                         *,\n",
    "                         topicGroupings: defaultdict) -> List[Tuple[str, str]] :    # path of all outputs\n",
    "                                                                                    # list[0]  = overall mardown\n",
    "                                                                                    # list[1:] = order of count\n",
    "                                                                                    # doesn't include markdown 'markdown/'\n",
    "    if not topicGroupings :\n",
    "        topicGroupings = getCompletedQuestionsTopicLists(questionData)\n",
    "\n",
    "    topicDataframes = questionTopicDataframes(questionData=questionData, topicGroupings=topicGroupings)\n",
    "\n",
    "    # For each topic case\n",
    "    NOTEBOOK_PATH = join(README_PATH, MARKDOWN_PATH, TOPIC_FOLDER)\n",
    "\n",
    "    # For the overal hosting markdown\n",
    "    OVERALL_FILE_NOTEBOOK_PATH = join(README_PATH, MARKDOWN_PATH, 'Topics.md')\n",
    "    OVERALL_FILE_README_PATH = join(MARKDOWN_PATH, 'Topics.md')\n",
    "\n",
    "    if not isdir(NOTEBOOK_PATH) :\n",
    "        mkdir(NOTEBOOK_PATH)\n",
    "\n",
    "    output = [OVERALL_FILE_README_PATH]\n",
    "    with open(OVERALL_FILE_NOTEBOOK_PATH, 'w', encoding='utf-8') as topic_file :\n",
    "        topic_file.write('# Topics\\n\\n')\n",
    "        topic_file.write('*[Back to top](<../README.md>)*\\n\\n')\n",
    "        topic_file.write('------\\n\\n')\n",
    "\n",
    "        for topic, cnt, df in topicDataframes :\n",
    "            file_name = f'{topic}.md'\n",
    "            notebook_path = join(NOTEBOOK_PATH, file_name)\n",
    "            readme_path = join(TOPIC_FOLDER, file_name)\n",
    "            with open(notebook_path, 'w', encoding='utf-8') as f :\n",
    "                url = f'https://leetcode.com/tag/{topic.replace(\" \", \"-\")}/'\n",
    "                f.write(f'# [{topic}](<{url}>) ({cnt} completed)\\n\\n')\n",
    "                f.write(f'*[Back to top](<../../README.md>)*\\n\\n')\n",
    "                f.write('------\\n\\n')\n",
    "                f.write(df.to_markdown(index=False))\n",
    "        \n",
    "            topic_file.write(f'- [{topic}](<{readme_path}>) ({cnt} completed)\\n')\n",
    "            output.append((topic, readme_path))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dailies, Recents, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_URL = ''\n",
    "\n",
    "def miscMarkdownGenerations(questionData:   dict,\n",
    "                            *,\n",
    "                            code_length:    bool = False,\n",
    "                            recent:         bool = False,\n",
    "                            daily:          bool = False) -> str : # output path\n",
    "    df = None\n",
    "    fileName = None\n",
    "    header_data = None\n",
    "    details = None\n",
    "\n",
    "    # print(f'{code_length, recent = }')\n",
    "    if code_length :\n",
    "        df = byCodeLengthDataDataframe(questionData)\n",
    "        fileName    = 'Questions_By_Code_Length.md'\n",
    "        header_data = '# Questions By Code Length\\n\\n'\n",
    "        details     = 'Calculations are based on the code files\\'s byte sizes.\\n\\n'\n",
    "    elif recent :\n",
    "        df = byRecentQuestionDataDataframe(questionData)\n",
    "        fileName    = 'Questions_By_Recent.md'\n",
    "        header_data = '# Most Recently Solved Questions\\n\\n'\n",
    "        details     = 'Calculations are based on the date of the first solve.\\n\\n'\n",
    "    elif daily :\n",
    "        dailyQuestionData = {}\n",
    "        for qNo, qData in questionData.items() :\n",
    "            if 'Daily' in qData['categories'] :\n",
    "                dailyQuestionData[qNo] = qData\n",
    "        df = byRecentQuestionDataDataframe(dailyQuestionData)\n",
    "        fileName    = 'Daily_Questions.md'\n",
    "        # header_data = f'# [Daily Questions](<{DAILY_URL}>)\\n\\n'\n",
    "        header_data = f'# Daily Questions\\n\\n'\n",
    "        details     = 'Dates are for the date I completed the ' + \\\n",
    "                      'question so due to the my time zone and how it lines up with ' + \\\n",
    "                      'UTC, it may be off by a day.\\n\\n'\n",
    "    else :\n",
    "        print('Error. No markdown generation specified.')\n",
    "        print()\n",
    "        return ''\n",
    "\n",
    "    # print(f'{fileName = }')\n",
    "\n",
    "    output_path = join(MARKDOWN_PATH, fileName)\n",
    "    readme_path = join(README_PATH, MARKDOWN_PATH, fileName)\n",
    "\n",
    "    with open(readme_path, 'w', encoding='utf-8') as f :\n",
    "        f.write(header_data)\n",
    "        f.write(f'*[Back to top](<../README.md>)*\\n\\n')\n",
    "        f.write(details)\n",
    "        f.write(df.to_markdown(index=False))\n",
    "\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputing to README File\n",
    "Takes all the above and overwrites the current [README.md](README.md) file with the data calculated above.\n",
    "\n",
    "Inputs values in order of:\n",
    "- Profile link\n",
    "- Stats\n",
    "- Stat clarification\n",
    "- Question link tables Easy-Medium-Hard\n",
    "\n",
    "Uses the built-in DataFrame `.to_markdown()` for outputting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportPrimaryReadme(dfQuestions:        DataFrame,\n",
    "                        *,\n",
    "                        additionalSorts:    List[str] = [],\n",
    "                        topicLinks:         List[Tuple[str, str]] = []) -> None :\n",
    "    readmePath = join(README_PATH, 'README.md')\n",
    "    print(readmePath)\n",
    "    with open(readmePath, 'w') as file :\n",
    "        username = getenv('LEETCODE_USERNAME')\n",
    "        file.write(f'# **[LeetCode Records](https://leetcode.com/u/{username}/)** ({len(dfQuestions.index)} solved)\\n\\n')\n",
    "\n",
    "        file.write(f'> My LeetCode Profile: [{username}](https://leetcode.com/u/{username}/)\\n\\n')\n",
    "\n",
    "        file.write('## About this Repo\\n\\n')\n",
    "        file.write('This repo is a collection of my LeetCode solutions, primarily written in Python, Java, and C. ' + \n",
    "                   'On any page, `click the main title` to be redirected to the official `LeetCode` page for the ' + \n",
    "                   'question, topic, list, etc. See the `Additional Categories` section for pages that group' + \n",
    "                   ' questions by different criteria -- e.g. by their *related topics*.')\n",
    "        file.write('\\n\\n\\n')\n",
    "\n",
    "        file.write('------\\n\\n')\n",
    "\n",
    "        file.write('## Category Notes\\n')\n",
    "        file.write('1. **Daily** - Daily challenge questions that were done on the day of\\n')\n",
    "        file.write('2. **Weekly Premium** - Weekly premium questions that were done on week of\\n')\n",
    "        file.write('3. **Contest** - Questions that I completed during a live contest\\n')\n",
    "        # file.write('4. **Favourite** - Questions that I liked and wanted to keep a record of\\n')\n",
    "        file.write('\\n\\n')\n",
    "\n",
    "        file.write('------\\n\\n')\n",
    "\n",
    "        file.write('## Additional Categories Stats\\n')\n",
    "\n",
    "        for altSorts in additionalSorts :\n",
    "            file.write(altSorts)\n",
    "            file.write('\\n\\n')\n",
    "        \n",
    "        if topicLinks :\n",
    "            file.write('------\\n\\n')\n",
    "            file.write(', '.join([f'[{topic}](<{join(MARKDOWN_PATH, link)}>)' for topic, link in topicLinks[1:]]))       \n",
    "            file.write('\\n\\n')\n",
    "            file.write('------\\n\\n')\n",
    "        \n",
    "        file.write('\\n\\n')\n",
    "\n",
    "        file.write('## Questions\\n')\n",
    "        file.write(dfQuestions.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculateAll: forces recalcualtion markdowns for each question irregardless if its\n",
    "#                 source files have been modified or not\n",
    "def main(*, recalculateAll: bool = False, noRecord: bool = False) -> None :\n",
    "    leetcodeFiles           = getCodeFiles()\n",
    "    additionalInfoFiles     = getContextFiles()     # For later use when generating the individual readme files\n",
    "\n",
    "    contestFolders          = getContestFolders()\n",
    "    contestLeetcodeFiles    = getContestFiles(contestFolders)\n",
    "\n",
    "    if USE_GIT_DATES :\n",
    "        getAllCTimesViaGit(additionalInfoFiles \n",
    "                           + leetcodeFiles \n",
    "                           + [join(x[0], x[1]) for x in contestLeetcodeFiles])\n",
    "\n",
    "\n",
    "    questionDetailsDict     = retrieveQuestionDetails()\n",
    "    questionTopicsDict      = retrieveQuestionTopics()\n",
    "\n",
    "    leetcodeFiles.sort()\n",
    "    contestLeetcodeFiles.sort()\n",
    "\n",
    "\n",
    "    # Files for leetcode questions found\n",
    "    print(f'Total of {len(leetcodeFiles)} files found.')\n",
    "\n",
    "    # Files in contest folders found\n",
    "    print(f'Total of {len(contestLeetcodeFiles)} contest files found.')\n",
    "\n",
    "\n",
    "    # Parsing primary files\n",
    "    fileLatestTimes = getRecentFileTimes() if (not recalculateAll and not noRecord) else {}\n",
    "\n",
    "    reprocessMarkdown = set()\n",
    "    questionData = {}\n",
    "\n",
    "    # Parsing primary files\n",
    "    print('Parsing code files...')\n",
    "    for leetcodeFile in leetcodeFiles :\n",
    "        parseCase(leetcodeFile=leetcodeFile,\n",
    "                  questionData=questionData,\n",
    "                  fileLatestTimes=fileLatestTimes, \n",
    "                  reprocessMarkdown=reprocessMarkdown,\n",
    "                  questionDetailsDict=questionDetailsDict)\n",
    "        \n",
    "    # Parsing contest files & folforders\n",
    "    print('Parsing contest files...')\n",
    "    for leetcodeContestFile in contestLeetcodeFiles :\n",
    "        contestFolder, leetcodeFile = leetcodeContestFile\n",
    "        parseCase(leetcodeFile=leetcodeFile,\n",
    "                  questionData=questionData,\n",
    "                  fileLatestTimes=fileLatestTimes,\n",
    "                  reprocessMarkdown=reprocessMarkdown, \n",
    "                  subFolderPath=contestFolder, \n",
    "                  questionDetailsDict=questionDetailsDict,\n",
    "                  contest=contestFolder)\n",
    "        \n",
    "\n",
    "    # Parsing additional information files\n",
    "    print('Parsing additional information/context files...')\n",
    "    parseContextFiles(txtFiles=additionalInfoFiles, \n",
    "                      questionData=questionData,\n",
    "                      fileLatestTimes=fileLatestTimes,\n",
    "                      reprocessMarkdown=reprocessMarkdown)\n",
    "    \n",
    "    # Identifying members of lists\n",
    "    print('Sorting questions to their lists...')\n",
    "    processListData(questionData=questionData)\n",
    "\n",
    "    # Generating markdowns for each individual question\n",
    "    print('Generating markdowns for each individual question...')\n",
    "    processMarkdownGeneration(questionData=questionData, \n",
    "                              reprocessMarkdown=reprocessMarkdown, \n",
    "                              questionDetailsDict=questionDetailsDict, \n",
    "                              questionTopicsDict=questionTopicsDict)\n",
    "    \n",
    "    # Produces a markdown where questions are sorted by the amount of code\n",
    "    # written for the question\n",
    "    # code_length_md_path = exportCodeLengthMarkdown(questionData)\n",
    "    print('Generating category lists...')\n",
    "    byCodeLength        = miscMarkdownGenerations(questionData, code_length=True)\n",
    "    byRecentlySolved    = miscMarkdownGenerations(questionData, recent=True)\n",
    "    dailyQuestions      = miscMarkdownGenerations(questionData, daily=True)\n",
    "    altSorts            = [f'- [Daily Questions](<{dailyQuestions}>)',\n",
    "                           f'- [Questions By Code Length](<{byCodeLength}>)',\n",
    "                           f'- [Questions By Recent](<{byRecentlySolved}>)']\n",
    "    \n",
    "\n",
    "    completedQsTopicGroupings = getCompletedQuestionsTopicLists(questionData)\n",
    "    topicMarkdownLinks = topicBasedMarkdowns(questionData, topicGroupings=completedQsTopicGroupings)\n",
    "    altSorts.append(f'- [Grouped by Topic](<{topicMarkdownLinks[0]}>)')\n",
    "\n",
    "\n",
    "    # Exporting the primary README.md file\n",
    "    print('Exporting primary README.md file...')\n",
    "    dfQuestions = convertQuestionDataToDataframe(questionData, includeDate=False, includeMarkdownFolder=True)\n",
    "    exportPrimaryReadme(dfQuestions, additionalSorts=altSorts, topicLinks=topicMarkdownLinks)\n",
    "\n",
    "\n",
    "    print(f'Number of individual questions updated/added: {len(reprocessMarkdown)}')\n",
    "\n",
    "\n",
    "    if not noRecord :\n",
    "        print('Pickling most recent modification times for future reference...')\n",
    "        writeRecentFileTimes(fileLatestTimes)           # restore for next use\n",
    "\n",
    "\n",
    "    print('All processes complete. Exiting...')\n",
    "    return questionData, reprocessMarkdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__' :\n",
    "    '''\n",
    "    ### Flags\n",
    "    `-r` : \n",
    "        Recalculate all markdown files irregardless of whether there are modified or new code files for that question or not\n",
    "    `-n` :\n",
    "        Don't use the previous modified dates and don't store them (in effect, the same as `-r` but it doesn't save the \n",
    "        new modification dates). Primarily for use with GitHub actions.\n",
    "    `-g` :\n",
    "        Uses the repository's git log history for each file to trace the creation and last modification dates of each file \n",
    "        rather than use the default `getctime()` and `getmtime()` of each file. GitHub actions seem to default the ctime \n",
    "        and mtimes to time.now due to not tracking the actual mtime ctime metadata.\n",
    "\n",
    "        WARNING: Only for use with GitHub actions as this ends up being very slow due to low subprocess speends.\n",
    "    '''\n",
    "    recalcaulateAll = False\n",
    "    noRecord = False\n",
    "\n",
    "    if not IS_NOTEBOOK :\n",
    "        parser = argparse.ArgumentParser()\n",
    "\n",
    "        parser.add_argument(\"-r\", \n",
    "                            help=\"Recompile all markdown files\", \n",
    "                            required=False, \n",
    "                            action=argparse.BooleanOptionalAction)\n",
    "        \n",
    "        parser.add_argument(\"-n\", \n",
    "                            help=\"Don't use the previous modified dates and don't store them\", \n",
    "                            required=False, \n",
    "                            action=argparse.BooleanOptionalAction)\n",
    "        parser.add_argument(\"-norecord\", \n",
    "                            help=\"Don't use the previous modified dates and don't store them\", \n",
    "                            required=False, \n",
    "                            action=argparse.BooleanOptionalAction)\n",
    "        parser.add_argument(\"-g\", \n",
    "                            help=\"Use Git repo's dates for determining if a file has been modified and created (WARNING SLOW)\", \n",
    "                            required=False, \n",
    "                            action=argparse.BooleanOptionalAction)\n",
    "        \n",
    "        recalcaulateAll = parser.parse_args().r\n",
    "        noRecord = parser.parse_args().norecord or parser.parse_args().n\n",
    "\n",
    "        USE_GIT_DATES = parser.parse_args().g\n",
    "\n",
    "    README_ABS_DIR = README_ABS_DIR[:README_ABS_DIR.rindex('/')]\n",
    "    print(README_ABS_DIR, '\\n')\n",
    "\n",
    "    print('No record'.ljust(20), 'on' if noRecord else 'off')\n",
    "    print('Recalculate'.ljust(20), 'on' if recalcaulateAll else 'off')\n",
    "    print('Use Git dates'.ljust(20), 'on' if USE_GIT_DATES else 'off')\n",
    "    print()\n",
    "\n",
    "\n",
    "    main(recalculateAll=recalcaulateAll, noRecord=noRecord)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
